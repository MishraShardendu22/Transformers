{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MishraShardendu22/Transformers/blob/main/Translate_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "-s3WHocWFOwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b70fe8e-00ab-40df-97d2-f1da8795ea45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Installing collected packages: torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "stIWG841FOak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IXxQHCoByXog"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets sentencepiece accelerate evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaination (ai help)\n",
        "\n",
        "```python\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "```\n",
        "\n",
        "### What it does\n",
        "\n",
        "It splits your dataset into two parts:\n",
        "\n",
        "* **90% → training set**\n",
        "* **10% → validation (test) set**\n",
        "\n",
        "Since you selected **30,000 samples**:\n",
        "\n",
        "* 27,000 → used to train the model\n",
        "* 3,000 → used to evaluate model performance\n",
        "\n",
        "---\n",
        "\n",
        "### Why this is required\n",
        "\n",
        "During training:\n",
        "\n",
        "* Model learns on the **train set**\n",
        "* After each epoch, performance is checked on the **validation set**\n",
        "* Prevents overfitting\n",
        "* Lets you measure BLEU score properly\n",
        "\n",
        "---\n",
        "\n",
        "### What `print(dataset)` shows\n",
        "\n",
        "You will see something like:\n",
        "\n",
        "```\n",
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ...\n",
        "        num_rows: 27000\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ...\n",
        "        num_rows: 3000\n",
        "    })\n",
        "})\n",
        "```"
      ],
      "metadata": {
        "id": "p5Hb88nvNnkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Correct dataset name\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
        "\n",
        "# Shuffle and take 1,000,000 samples\n",
        "dataset = dataset[\"train\"].shuffle(seed=42).select(range(1_000_000))\n",
        "\n",
        "# Train-validation split\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "LBH8rvVi50R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    EncoderDecoderConfig,\n",
        "    EncoderDecoderModel,\n",
        "    BertConfig\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "encoder_config = BertConfig(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        "    max_position_embeddings=512,\n",
        ")\n",
        "\n",
        "decoder_config = BertConfig(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        "    is_decoder=True,\n",
        "    add_cross_attention=True,\n",
        "    max_position_embeddings=512,\n",
        ")\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
        "    encoder_config,\n",
        "    decoder_config\n",
        ")\n",
        "\n",
        "model = EncoderDecoderModel(config=config)\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "xyBGu7-T6vdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [x[\"hi\"] for x in examples[\"translation\"]]\n",
        "    targets = [x[\"en\"] for x in examples[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        targets,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    num_proc=2\n",
        ")\n",
        "\n",
        "print(tokenized_dataset)"
      ],
      "metadata": {
        "id": "6Rzn7NKtAJP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./scratch-hi-en\",\n",
        "    eval_strategy=\"steps\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=1000,\n",
        "    save_steps=5000,\n",
        "    eval_steps=5000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready\")"
      ],
      "metadata": {
        "id": "hbsZPWHbAJrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "rGYiy9AyAn4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.bos_token_id = tokenizer.cls_token_id"
      ],
      "metadata": {
        "id": "wpAPiBOMf0c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"हैलो आप कैसे हैं\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    truncation=True\n",
        ").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_length=128,\n",
        "    decoder_start_token_id=tokenizer.cls_token_id,\n",
        "    bos_token_id=tokenizer.cls_token_id,\n",
        "    eos_token_id=tokenizer.sep_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Translation:\", translation)"
      ],
      "metadata": {
        "id": "c17qp8X1AiFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}